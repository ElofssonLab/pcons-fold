We thank all reviewers for valuable suggestions. All changes are
marked with red in the manuscript.


----------------------- REVIEW 1 ---------------------
PAPER: 64
TITLE: PconsFold: Improved contact predictions improve  protein models
AUTHORS: Mirco Michel, Sikander Hayat, Marcin J. Skwark, Chris Sander, Debora S. Marks and Arne Elofsson

OVERALL EVALUATION: -1 (weak reject: solid work, but with small potential for a good presentation)
REVIEWER'S CONFIDENCE: 5 (expert)

----------- REVIEW -----------

The authors describe the latest addition to the Pcons family of tools
for protein structure prediction, PconsFold, which builds on advances
in intra-chain contact prediction and in de-novo protein structure
modelling. PconsFold feeds the output of PconsC, a consensus-based
approach for protein contact predictions previously described by the
same research group, to Rosetta. Benchmarking results show that the
program generates more accurate 3D models than EVfold, in line with
previous independent studies.

The manuscript describes solid work which reflects the authors’ track
record in setting up effective and efficient meta-predictors. The
presentation is clear and the question addressed is certainly of
interest to the structural bioinformatics community.

The authors may want to consider these suggestions to improve the presentation of their work.

1. It might be useful to give readers some additional statistics about
   the scope and usefulness of the proposed tool. How many protein
   domain families (excluding those used as benchmark) have no member
   of known structure but sufficiently large size to benefit from
   plmDCA and PSICOV? How about the size of the target proteins? The
   large benchmark set only includes single domain protein chains of
   roughly 250 residues. How feasible would the modelling of larger
   proteins be?

According to a study by Kamisetty et al.
(http://www.pnas.org/content/early/2013/09/04/1314045110) there are
422 protein families without known structure and enough sequences to
successfully apply sequence-based contact prediction. The proteins
from our benchmark all have known structures and are thus not included
in this number. Theoretically, there is no upper limit to protein
length for PconsFold, assuming the alignments are of sufficient depth.
However, in practice we noticed two issues that might limit the
applicability of PconsFold in terms of protein length: (i) the runtime
of PSICOV and especially plmDCA will increase dramatically with the
length of proteins. (ii) Rosetta might need to compute more than 2000
decoys to converge. The first issue can be tackled by further
optimizing contact prediction methods (e.g. using the newer
"asymmetric" version of plmDCA). Another stopping criterion for
Rosetta could resolve the latter issue (at least regarding model
quality). We updated the manuscript accordingly and included
necessary references. 


2. Some results could be discussed more thoroughly – e.g. the quality
   of alpha helical protein models is higher than that of chains in
   other structural classes, despite the fact the precision of the
   predicted contact maps for alpha helical proteins is not
   substantially higher. How would the authors go about getting even
   better models, maybe by satisfying more residue-residue contacts or
   more long-range contacts?

The higher quality predictions of all alpha proteins are to our extend
of knowledge due to the difficulty of satisfying long range beta-beta
interactions during folding. We think that especially in beta-sheet
containing proteins accurate long-range contacts are of high value. We
are currently trying to improve the behavior of PconsFold on such
proteins. There are several ways to achieve this goal, such as
improving beta-beta contact predictions or changing type or weight of
such contacts in Rosetta. We are in the process of retraining a
version PconsC to be specialized for beta-beta contacts.  From such
improved contacts we are hopefully able to infer hydrogen bonding
patterns in beta sheets. Hydrogen bonds will then be provided as
strong additional constraints to Rosetta. We updated the manuscript to
discuss this topic more thoroughly.


3. Some statements do not appear to be supported by the data
   shown. The values in Table 1 do not appear to support the statement
   “For PconsFold and Rosetta/plmDCA the internal scoring was able to
   pick the best model on average” nor do the following
   figures. Hopefully the authors will be able to improve this point.

We are sorry for the misconception of this sentence. By "best models
on average" we meant the highest ranked models from the internal
scoring were on average better than the models selected by other
scoring methods. We rephrased the sentence into: "For PconsFold and
Rosetta/plmDCA the internal scoring performed best, which is indicated
by the highest average TM-scores in Table 1.". Hopefully this enhances
understandability of the text.


4. While the Rosetta development team may be glad to read that
   “Rosetta models are chemically more correct”, it is fair to say
   that 1) accurate model stereochemistry is useful only if the
   overall fold is correctly predicted; 2) MolProbity essentially
   evaluates the compatibility of some features of the input protein
   models with those observed in a large reference set of known
   protein structures. There are several known protein structures that
   contain no experimental artefacts and yet deviate more or less
   substantially from such distributions.

1) Thank you for pointing that out, we updated the manuscript
accordingly. We decided to include this analysis, since the predicted
models reach TM-scores of 0.5 and higher, which indicates correctly
predicted folds.
2) Additionally, we ran PROCHECK on the relaxed models (same input as
for Molprobity). The results show the same overall trend of Rosetta
models being stereochemically more correct and thus support our
point. We updated the manuscript accordingly.


5. PconsFold is made available to the community in the form of a
   source code. For a majority of ECCB participants and Bio
   informatics readers, setting up their own pipeline would not be
   difficult - though having a freely available tool is undoubtedly
   convenient. That would leave as the main audience experimental
   biologists, which would certainly prefer a web-based application.

We are currently working on making the tool available as an online
service. However, the computational demand is rather large marking it
necessary to find funding to provide this service. Hopefully we can
provide this shortly.



----------------------- REVIEW 2 ---------------------
PAPER: 64
TITLE: PconsFold: Improved contact predictions improve  protein models
AUTHORS: Mirco Michel, Sikander Hayat, Marcin J. Skwark, Chris Sander, Debora S. Marks and Arne Elofsson

OVERALL EVALUATION: 3 (strong accept: outstanding work which will make an excellent presentation)
REVIEWER'S CONFIDENCE: 5 (expert)

----------- REVIEW ----------- 

The paper is written on the hot topic of how improving accuracy of
contact predictions can help structure prediction. The authors use a
hybrid protocol PconsFold combining the contact predictor PconsC with
Rosetta protocol for ab initio structure prediction. It is shown that
such a combination indeed improves accuracy of structure models and
yields comparable or even slightly better results than similar hybrid
approaches based on recently published correlated mutations
methods. The authors argue that a better decoy sets and improved
folding protocols can further improve accuracy of models. The paper is
well written and provides enough data to substantiate the conclusions
reached.


THANKS!


----------------------- REVIEW 3 ---------------------
PAPER: 64
TITLE: PconsFold: Improved contact predictions improve  protein models
AUTHORS: Mirco Michel, Sikander Hayat, Marcin J. Skwark, Chris Sander, Debora S. Marks and Arne Elofsson

OVERALL EVALUATION: 2 (accept: very good work, with potential for a very good presentation)
REVIEWER'S CONFIDENCE: 5 (expert)

----------- REVIEW -----------

Overall a nicely written paper and technically sound study. The title
seems intuitively obvious title but it is good to see improvements
confirmed and quantified.

1. The abstract is quite technical - maybe explain what each of the
methods mentioned actually do for more general readers.

We have edited the abstract accordingly.


2. In section 2.1 the authors state “Due to technical reasons…” this is
vague please explain.

We now included 1JBE to all results and updated the figures
accordingly. This sentence was removed from the manuscript. 


3. In section 2.2 the equation n=f.l is also vague - perhaps show a
worked example.

4. Typo in section 2.4 “folding” not “foldig”.

5. In section 2.7 you could refer to figure 2.

Thank you! We included your suggestions in the manuscript and fixed
the error.


6. In Figure 2b why is only a subset of proteins used - is the effect
not seen on the other proteins?

A subset is used due to limitations in computational time. However, we
also ran the predictions exemplary for a well-depth of -1.0 on the
full dataset. This resulted in a TM-score of 0.28. Thus, the effect
is seen on the other proteins as well. We also extended the text to answer
this question.


7. Does Supplementary Table 1 exist?

Yes, it can be found in supplementary.pdf.


8. In section 3.1, 5th paragraph, 1st sentence could be reworded “In
addition, improvements in contact prediction methods further increases
the quality…”

Thanks for noting this. It has been fixed.


9. Figure 3a is interesting and a nice way to compare approaches on the
same plot. Perhaps you could show how the individual confidence score
cutoffs related to the TM-scores? Can you give optimal confidence
score cut-offs for each contact method? 

We have added standard errors to the plot.


10. In section 3.2 again “Due to technical reasons…” be more specific.

We have expanded these sentences. 


11. Table 1 is not totally clear. What is the baseline score for each
method column? Perhaps use a more descriptive title.

We have added the information for Rosetta without contact predictions alone.


12. Finally, the data set is quite small - are the differences observed significant?

Regarding Table 1: an all-to-all pairwise t-test analysis of the
differences in TM-score showed that the difference is significant with
>95% confidence if its absolute value is 0.02 or larger. Table 2: Here
did all-against-all one-sample t-tests of the TM-score difference.
This revealed that the difference between two TM-score values is
significant with $>$95\% confidence if its absolute value is 0.02 or
above. We updated the manuscript accordingly.

